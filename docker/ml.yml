# ML services - enabled via profiles
# Use COMPOSE_PROFILES environment variable or --profile flag

services:
  colpali:
    container_name: colpali
    build:
      context: ../colpali
      dockerfile: Dockerfile
    image: colpali:latest
    ports:
      - "7000:7000"
    env_file:
      - ../colpali/.env
    environment:
      - HUGGINGFACE_HUB_CACHE=/data/hf-cache
    volumes:
      - hf_cache:/data/hf-cache
    networks:
      - snappy-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    profiles:
      - minimal
      - ml
      - full
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  deepseek-ocr:
    container_name: deepseek-ocr
    build:
      context: ../deepseek-ocr
      dockerfile: Dockerfile
    image: deepseek-ocr:latest
    ports:
      - "8200:8200"
    env_file:
      - ../deepseek-ocr/.env
    environment:
      - HUGGINGFACE_HUB_CACHE=/data/hf-cache
    volumes:
      - hf_cache:/data/hf-cache
    networks:
      - snappy-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8200/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    profiles:
      - ml
      - full
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


volumes:
  hf_cache:

networks:
  snappy-network:
    driver: bridge
