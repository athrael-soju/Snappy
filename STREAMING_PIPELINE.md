# Streaming Pipeline Architecture

## ğŸ“Š Visual Timeline Comparison

### Current Batch Pipeline (100-page PDF)
```
Time â†’
0s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Rasterize ALL pages (1-100)                         60s     â”‚ â† BLOCKING
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

60s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Batch 1      â”‚ Embed â†’ Store â†’ OCR â†’ Upsert (12s)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

72s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Batch 2      â”‚ Embed â†’ Store â†’ OCR â†’ Upsert (12s)
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

... (continues for 25 batches)

360s (6 minutes) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                                                             Done âœ“

âš ï¸ Problems:
- First results: 72 seconds (user waits!)
- GPU idle for 60 seconds
- CPU idle during embedding
- Total time: 360 seconds
```

### New Streaming Pipeline (100-page PDF)
```
Time â†’
0s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Rasterize 1-4   â”
                   â”‚ â†’ [Queue] â†’ Embed 1-4        â”
2s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”˜            Store 1-4  â”      â”‚
   Rasterize 5-8   â”            OCR 1-4    â”‚      â”‚ â†’ Upsert 1-4 â”
                   â”‚                        â”‚      â”‚              â”‚
4s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”˜          â†’ Embed 5-8   â”‚      â”‚              â”‚
   Rasterize 9-12  â”            Store 5-8  â”‚      â”‚              â”‚
                   â”‚            OCR 5-8    â”˜      â”‚              â”‚
6s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”˜                              â”˜              â”‚
   Rasterize 13-16 â”          â†’ Embed 9-12                       â”‚
                   â”‚            Store 9-12                       â”‚
8s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”˜            OCR 9-12     â†’ Upsert 5-8        â”‚
   ...                                                           â”‚
                                                                 â”˜
10s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    âœ… FIRST RESULTS VISIBLE (pages 1-4 searchable!)

... (pipeline continues streaming)

60s â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
                                                             Done âœ“

âœ… Benefits:
- First results: 10 seconds (7x faster!)
- All resources busy (GPU, CPU, I/O)
- Progressive feedback
- Total time: 60 seconds (6x faster!)
```

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PDF Document                                 â”‚
â”‚                      document_id: abc-123                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  STAGE 1: PDF Rasterizer (Producer)           â”‚
        â”‚  Thread: Main thread                           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚ for page_batch in 1..100 (chunks of 4):  â”‚ â”‚
        â”‚  â”‚   convert_from_path()                     â”‚ â”‚
        â”‚  â”‚   rasterize_queue.put(batch)              â”‚ â”‚
        â”‚  â”‚   # Continues immediately!                â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   rasterize_queue            â”‚ â† Bounded (max 8 batches)
          â”‚   [batch1, batch2, batch3]   â”‚   Provides backpressure
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                â”‚                    â”‚
        â–¼                                â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2a: Embed   â”‚      â”‚ STAGE 2b: Storage    â”‚  â”‚ STAGE 2c: OCR    â”‚
â”‚ Thread: embed-1   â”‚      â”‚ Thread: storage-1    â”‚  â”‚ Thread: ocr-1    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ batch=queue.getâ”‚ â”‚      â”‚ â”‚ batch=queue.get  â”‚ â”‚  â”‚ â”‚batch=queue.getâ”‚ â”‚
â”‚ â”‚ embed(batch)  â”‚ â”‚      â”‚ â”‚ minio.store()    â”‚ â”‚  â”‚ â”‚ocr.process()  â”‚ â”‚
â”‚ â”‚ queue2.put()  â”‚ â”‚      â”‚ â”‚ (fail-fast)      â”‚ â”‚  â”‚ â”‚(fail-fast)    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                   (Parallel)                 (Parallel)
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ embedding_queue â”‚
â”‚ [emb1, emb2]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: Upsert Stage (only waits for embeddings)                â”‚
â”‚  Thread: upsert-1                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ embedded_batch = queue.get()  # Only waits for embeddings    â”‚ â”‚
â”‚  â”‚ urls = generate_urls(doc_id, page_ids)  # Dynamic generation â”‚ â”‚
â”‚  â”‚ ocr_urls = generate_ocr_urls(doc_id, page_nums)  # Dynamic   â”‚ â”‚
â”‚  â”‚ points = build_points(embeddings, urls, ocr_urls)            â”‚ â”‚
â”‚  â”‚ qdrant.upsert(points)                                        â”‚ â”‚
â”‚  â”‚ update_progress()                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow Example

**Single Batch Journey** (document_id: `doc-123`, batch_id: `0`, pages 1-4):

```
T=0s:  Rasterizer produces PageBatch
       â†’ {doc_id: "doc-123", batch_id: 0, images: [img1, img2, img3, img4]}
       â†’ Pushes to rasterize_queue

T=0s:  THREE consumers pull from rasterize_queue simultaneously:

       â”Œâ”€ Embed Stage:   Gets batch â†’ embeds â†’ produces EmbeddedBatch
       â”‚                 â†’ {doc_id: "doc-123", batch_id: 0, embeddings: [...]}
       â”‚                 â†’ Pushes to embedding_queue
       â”‚
       â”œâ”€ Storage Stage: Gets batch â†’ stores in MinIO (fails-fast on error)
       â”‚                 â†’ Uploads images to minio/doc-123/1/image/uuid1.jpg, etc.
       â”‚
       â””â”€ OCR Stage:     Gets batch â†’ processes OCR â†’ stores in MinIO (fails-fast on error)
                         â†’ Stores OCR JSON at minio/doc-123/1/ocr.json, etc.

T=5s:  Embedding complete

T=5s:  Upsert Stage:    Gets EmbeddedBatch from embedding_queue
                        â†’ Generates URLs dynamically from metadata
                        â†’ image_urls = ["http://minio/doc-123/1/image/uuid1.jpg", ...]
                        â†’ ocr_urls = ["http://minio/doc-123/1/ocr.json", ...]
                        â†’ Builds Qdrant points with embeddings and URLs
                        â†’ Upserts to Qdrant
                        â†’ Updates progress

T=6s:  âœ… Pages 1-4 are searchable!

Note: All stages run in parallel. Any failure stops the pipeline to ensure data consistency.
```

**Key Insight**: All stages run **independently in parallel** with dedicated queues - URLs are generated dynamically!

## ğŸ’» Usage Example

```python
from domain.pipeline.streaming_pipeline import StreamingPipeline
from api.dependencies import (
    get_colpali_client,
    get_minio_service,
    get_ocr_service,
    get_qdrant_service,
)
from clients.qdrant.indexing.points import PointFactory

# Initialize services
embedding_processor = get_qdrant_service().embedding_processor
image_store = get_qdrant_service()._pipeline._batch_processor.image_store
ocr_service = get_ocr_service()
point_factory = PointFactory()
qdrant_service = get_qdrant_service().service
collection_name = config.QDRANT_COLLECTION_NAME

# Create streaming pipeline
pipeline = StreamingPipeline(
    embedding_processor=embedding_processor,
    image_store=image_store,
    ocr_service=ocr_service,
    point_factory=point_factory,
    qdrant_service=qdrant_service,
    collection_name=collection_name,
    batch_size=4,
    max_queue_size=8,  # Backpressure: max 8 batches in queue
)

# Start consumer threads
pipeline.start()

# Process PDF (rasterizer feeds the pipeline)
total_pages = pipeline.process_pdf(
    pdf_path="/tmp/document.pdf",
    filename="document.pdf",
    progress_callback=lambda current, total: print(f"{current}/{total}"),
    cancellation_check=lambda: check_if_cancelled(),
)

# Wait for pipeline to finish processing
pipeline.wait_for_completion()

# Clean up
pipeline.stop()

print(f"Processed {total_pages} pages")
```

## âš¡ Performance Characteristics

### Throughput Analysis

**Current Batch Pipeline**:
- Batch processing time: 12 seconds/batch
- Throughput: 4 pages / 12 seconds = **0.33 pages/second**
- 100 pages: ~6 minutes
- 1000 pages: ~60 minutes

**Streaming Pipeline** (4 concurrent stages):
- First batch: 10 seconds (startup latency)
- Steady state: 4 pages / 2 seconds = **2 pages/second** (6x faster!)
- 100 pages: ~60 seconds (includes 10s startup)
- 1000 pages: ~510 seconds (~8.5 minutes, 7x faster!)

### Resource Utilization

**Current Pipeline**:
```
CPU:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ_____  (50% - idle during GPU ops)
GPU:    _____â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (50% - idle during PDF conversion)
I/O:    ___â–ˆâ–ˆâ–ˆ____  (30% - sporadic)
Memory: â–ˆâ–ˆâ–ˆ_______  (30% - spikes during batch load)
```

**Streaming Pipeline**:
```
CPU:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (95% - always rasterizing)
GPU:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (95% - always embedding/OCR)
I/O:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  (95% - continuous uploads)
Memory: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ____  (60% - bounded queues prevent overflow)
```

## ğŸ›ï¸ Tuning Parameters

### Queue Size (Backpressure Control)
```python
max_queue_size=8  # Default

# Small documents (<50 pages): 4
# Medium documents (50-200 pages): 8
# Large documents (200+ pages): 16
# Very large (1000+ pages): 32

# Trade-off: Larger queues = more memory, more parallelism
```

### Batch Size
```python
batch_size=4  # Default

# High-memory GPUs: 8
# Low-memory GPUs: 2
# CPU-only: 1

# Trade-off: Larger batches = better GPU utilization, more memory
```

### Worker Threads
```python
# PDF rasterization
worker_threads = os.cpu_count()  # Default: all cores

# OCR parallelism per batch
DEEPSEEK_OCR_MAX_WORKERS = 2  # Reduced to prevent GPU contention

# MinIO upload parallelism
MINIO_WORKERS = 8  # Moderate to prevent connection exhaustion
```

## ğŸ› Error Handling

### Stage Failures

**Embedding Stage Fails**:
- Pipeline stops (critical - can't proceed without embeddings)
- Already-processed batches remain in Qdrant

**Storage Stage Fails**:
- Pipeline stops (critical - cannot generate valid image URLs)
- Prevents creation of Qdrant points with broken image references

**OCR Stage Fails**:
- If OCR is enabled: Pipeline stops (critical - OCR was explicitly requested)
- If OCR is disabled: Stage doesn't run at all
- No silent fallbacks - failures are explicit

**Upsert Stage Fails**:
- Pipeline stops (critical - embeddings must be stored)
- Can retry from scratch (no caching needed)

### Cancellation

```python
def cancellation_check():
    if progress_manager.is_cancelled(job_id):
        raise CancellationError("Job cancelled")

pipeline.process_pdf(
    pdf_path=path,
    filename=filename,
    cancellation_check=cancellation_check,  # Check before each batch
)
```

When cancelled:
- Rasterizer stops immediately
- In-flight batches complete
- Queues drain gracefully
- Partial results remain in Qdrant (by design)

## ğŸ“ˆ Monitoring

### Queue Depth
```python
# Add to progress callback
progress_callback(
    current=pages_processed,
    message={
        "rasterize_queue": pipeline.rasterize_queue.qsize(),
        "embedding_queue": pipeline.embedding_queue.qsize(),
    }
)
```

### Stage Timing
```python
# All stages use @log_execution_time decorator
# Logs appear as:
# [INFO] Embedding batch 5 completed in 4.2s
# [INFO] Storage batch 5 completed in 1.1s
# [INFO] OCR batch 5 completed in 6.8s
# [INFO] Upsert batch 5 completed in 0.9s
```

### Bottleneck Detection
```
If rasterize_queue is always empty:
  â†’ Rasterization is bottleneck (increase worker_threads)

If rasterize_queue is always full:
  â†’ Downstream stages are bottleneck (reduce batch_size or add workers)

If embedding_queue is always full:
  â†’ Upsert is bottleneck (increase buffer_size for batched upserts)
```

## ğŸ”„ Migration Path

### Phase 1: Testing (1-2 days)
1. Deploy streaming pipeline alongside existing pipeline
2. Test with small documents (10-50 pages)
3. Compare results with existing pipeline
4. Validate: embeddings, URLs, OCR all correct

### Phase 2: Gradual Rollout (3-5 days)
1. Add feature flag: `USE_STREAMING_PIPELINE=true/false`
2. Route 10% of traffic to streaming pipeline
3. Monitor errors, performance
4. Gradually increase to 100%

### Phase 3: Cleanup (1 day)
1. Remove old batch pipeline code
2. Remove feature flag
3. Update documentation

## ğŸš€ Next Optimizations

After streaming pipeline is stable:

1. **Async HTTP Clients**: Replace `requests` with `httpx.AsyncClient`
2. **Process Pool for PDF**: Offload rasterization to separate processes
3. **Distributed Queue**: Replace in-memory queues with Redis for multi-instance support
4. **Adaptive Batch Sizing**: Dynamically adjust based on GPU memory usage
5. **Result Streaming**: WebSocket updates to frontend as pages complete
